<html>
<head>
 <title>Artificial intelligence (CK0031/CK0248)</title>
 <link rel=StyleSheet href="style.css" type="text/css" media=screen>
</head>

<body>
 <a name="top"></a>
 <h1>Artificial intelligence (CK0031/CK0248)</h1>

 The course overviews selected topics in artificial intelligence. The course deals with some of the central principles of AI, including search and problem-solving methods, reasoning and decision making under uncertainty:
 <ol>
  <li> <bold>Agents and environment</bold>: Rationality, Nature of the environment, Structure of the agents;
  <li> <bold>Probabilistic reasoning</bold>: Representation and inference in probabilistic models;
  <li> <bold>Problem solving</bold>: Searching discrete environments and numerical optimisation.
 </ol>
 What the course does not deal with is Logic and Machine Learning. We offer more suitable courses to study those topics.
 <br><br>
 Stuff from the past: Previous editions for <a href="2016_2/index.html">2016.2</a>  and <a href="2017_2/index.html">2017.2</a> (internal links may need adjustment.)
 <br><br>
 <iframe src="https://www.youtube.com/embed/qTrqmNieVKI" width="800" height="449" frameborder="5" allowfullscreen></iframe>
 <br><br>
 <bold>Instructor <font color=#333>&#9822;</font>:</bold> <a href="http://fkorona.github.io">Francesco Corona</a> (FC): francesco d&ouml;t corona &auml;t ufc d&ouml;t br
 <br><br>
 <bold> Physical location <font color=#333>&#9820;</font>:</bold> Monday, Wednesday and Friday 08:00-10:00. Bloco 915, Sala 1074.
 <ul>
  <li> There will no class on Mondays
  <li> LEC I is available on Mondays for independent work/study and on Wednesdays for practical sessions.
 </ul>
 <bold> Internet location <font color=#333>&#9814;</font>:</bold> Here! Or, <a href="https://si3.ufc.br/sigaa/public/home.jsf">here</a> (CK0031/CK0248) for mambojumbo related to administration.
 <br><br>
 <bold>Evaluation <font color=#333>&#9997;</font>:</bold> Approximately half a dozen theoretical and practical problem sets will be assigned as homework: Home assignments are for training but are not mandatory, they can be handed-in but they will not be evaluated. The actual evaluation will be based on two or three partial evaluations (APs) in class (weight 70%) and a final project (weight 30%). If needed a final evaluation (AF) will be arranged.
 <br><br>

 <hr id="dash">
 Go to: &nbsp;
 <a href="#Lectures">Lectures and schedule</a> |
 <a href="#Assignments">Problem sets</a> |
 <a href="#Material">Supplementary material</a> |
 <a href="#Pops">As it pops out</a> |
 <hr id="dash">

 <h2>News</h2>
 <font color="red"> >>>>> AP 01 -- OCT 10 <<<<< </font> (<a href="2018_2/Lecture_notes/02a_Unconstrained_optimisation.pdf">Unconstrained optimisation</a> -- Bloco 915, Sala 1074)
 <br><br>
 <font color="orange"> >>>>> <a href="2018_2/Exercise_sheets/CK0031_CK0248_E01_2018_2.pdf">Exercise 01</a> <<<<< </font> (Linear algebra and coding revision: Vectors)
 <br>
 <font color="orange"> >>>>> <a href="2018_2/Exercise_sheets/CK0031_CK0248_E02_2018_2.pdf">Exercise 02</a> <<<<< </font> (Linear algebra and coding revision: Matrices)
 <br>
 <font color="orange"> >>>>> <a href="2018_2/Exercise_sheets/CK0031_CK0248_E03_2018_2.pdf">Exercise 03</a> <<<<< </font> (Unconstrained optimisation: Line-search methods)
 <br>
 <font color="orange"> >>>>> <a href="2018_2/Exercise_sheets/CK0031_CK0248_E04_2018_2.pdf">Exercise 03</a> <<<<< </font> (Probability tables)
 <br>

 <a name="Lectures"></a>
 <h2>Lectures and schedule</h2>
 <ol start="0">

  <li><bold>About this course</bold>
  <br><br>
  <table id="bord" style="width: 100%;">
  <tr id="bord">
   <td id="bord" style="width: 10%;">A
   </td>
   <td id="bord" style="width: 35%;"><bold>About this course</bold> (FC)
   </td>
   <td id="bord" style="width: 55%;">
   <ul>
    <li> About the type of artificial intelligence that we shall study and the type that we shall not study in this course
   </ul>
   </td>
   </tr>
   </table>
   <br>
   <ul>
    <li> <a href="2018_2/Lecture_notes/00_Intro.pdf">Intro</a> (AUG 08/10)
   </ul>
   <br>

  <li><bold>Agents and environment</bold>
  <br><br>
  <table id="bord" style="width: 100%;">
  <tr id="bord">
  <td id="bord" style="width: 10%;">A
  </td>
  <td id="bord" style="width: 35%;"><bold>Agents and environments</bold> (FC)
  </td>
  <td id="bord" style="width: 55%;">
  <ul>
   <li> Structure of agents, nature of environments
  </ul>
  </td>
  </tr>
  </table>
  <br>
  <ul>
   <li> <a href="2018_2/Lecture_notes/01_Agents_and_environment.pdf">Agents and environment</a> (AUG 22/24)
  </ul>
  <br>

  <li> <bold>Probabilistic reasoning</bold> (Elements of probabilistic modelling, inference in probabilistic models)
  <br><br>
  <table id="bord" style="width: 100%;">
  <tr id="bord">
  <td id="bord" style="width: 10%;">A
  </td>
  <td id="bord" style="width: 35%;"><bold>Probabilistic reasoning</bold> (FC)
  </td>
  <td id="bord" style="width: 55%;">
  <ul>
  <li> Probability refresher
   <li> Probabilistic reasoning, prior, likelihood and posterior
  </ul>
  </td>
  </tr>

  <tr id="bord">
  <td id="bord" style="width: 10%;">B</td>
  <td id="bord" style="width: 35%;"><bold>Graph concepts</bold> (FC)
  </td>
  <td id="bord" style="width: 55%;">
  <ul>
   <li> Definitions, numerical encoding (edge lists, adjacency matrices, clique matrices)
  </ul>
  </td>
  </tr>

  <tr id="bord">
  <td id="bord" style="width: 10%;">C
  </td>
  <td id="bord" style="width: 35%;"><bold>Belief networks</bold> (FC)
  </td>
  <td id="bord" style="width: 55%;">
  <ul>
   <li> Structure (independencies and specifications)
   <li> Belief networks (conditional independence, collisions, path manipulations for independence, d-separation, graphical and distributional in/dependence, Markov equivalence, expressibility)
   <li> Causality (Simpson's paradox, do-calculus, influence diagrams)
  </ul>
  </td>
  </tr>

  <tr id="bord">
  <td id="bord" style="width: 10%;">D
  </td>
  <td id="bord" style="width: 35%;"><bold>Inference in trees</bold> (FC)
  </td>
  <td id="bord" style="width: 55%;">
  <ul>
   <li> Marginal inference (Variable elimination in a Markov chain and message passing, the sum-product algorithm of factor graphs, evidence, marginal likelihood, loops)
   <li> Forms of inference (max-product, $N$ most probable states, most probable path and shortest path, mixed inference)
  </ul>
  </td>
  </tr>
  </table>
  <br>

  <li> <bold>Problem solving</bold> (Solving by searching, local search, numerical optimisation)
  <br><br>
  <table id="bord" style="width: 100%;">
  <tr id="bord">
  <td id="bord" style="width: 10%;">A
  </td>
  <td id="bord" style="width: 35%;"><bold>Unconstrained optimisation</bold> (FC)
  </td>
  <td id="bord" style="width: 55%;">
  <ul>
   <li> Derivative-free methods (golden section and quadratic interpolation, Nelder and Mead)
   <li> The Newton's method
   <li> Line-search or descent methods (descent directions, strategies for choosing the step-length, the descent method with Newton's directions, descent methods with quasi-Newton's directions, gradient and conjugate-gradient descent methods)
   <li> Trust-region methods
   <li> The non-linear least-squares method (the Gauss-Newton method, the Levenberg-Marquardt method)
  </ul>
  </td>
  </tr>

  <tr id="bord">
  <td id="bord" style="width: 10%;">B
  </td>
  <td id="bord" style="width: 35%;"><bold>Constrained optimisation</bold> (FC)
  </td>
  <td id="bord" style="width: 55%;">
  <ul>
   <li> The penalty function method
   <li> The augmented Lagrangian method
  </ul>
  </td>
  </tr>
  </table>
  <br>
  <ul>
   <li> Lecture notes: <a href="2018_2/Lecture_notes/02a_Unconstrained_optimisation.pdf">Unconstrained optimisation</a> (Last update SEP 24 | AUG 31, SEP 14, SEP 26, ...)
    <li> Lecture notes: <a href="2018_2/Lecture_notes/02b_Constrained_optimisation.pdf">Constrained optimisation</a> (Last update OCT 30 | OCT 31)
    <li> Assignments - Linear algebra and coding revision: <a href="2018_2/Exercise_sheets/CK0031_CK0248_E01_2018_2.pdf">Part 1</a>, <a href="2018_2/Exercise_sheets/CK0031_CK0248_E02_2018_2.pdf">Part 2</a> (AUG 29, SEP 05, ...)
     <li> Assignments - Unconstrained optimisation: <a href="2018_2/Exercise_sheets/CK0031_CK0248_E03_2018_2.pdf">Part 1</a> (OCT 03)
  </ul>
  <br>

  <table id="bord" style="width: 100%;">
  <tr id="bord">
  <td id="bord" style="width: 10%;">A
  </td>
  <td id="bord" style="width: 35%;"><bold>Problems, solutions and problem-solving agents</bold> (FC)
  </td>
  <td id="bord" style="width: 55%;">
  <ul>
   <li> Problems, solutions and problem-solving agents
   <li> Search algorithms
  </ul>
  </td>
  </tr>

  <tr id="bord">
  <td id="bord" style="width: 10%;">B
  </td>
  <td id="bord" style="width: 35%;"><bold>Uninformed search strategies</bold> (FC)
  </td>
  <td id="bord" style="width: 55%;">
  <ul>
   <li> Breadth-first search, uniform-cost search
   <li> Depth-first search, depth-limited search, iterative deepening depth-first search, bidirectional search
  </ul>
  </td>
  </tr>

  <tr id="bord">
  <td id="bord" style="width: 10%;">C
  </td>
  <td id="bord" style="width: 35%;"><bold>Informed search strategies</bold> (FC)
  </td>
  <td id="bord" style="width: 55%;">
  <ul>
   <li> Greedy best-first search, $A^*$ search
   <li> Memory-bounded heuristic search
  </ul>
  </td>
  </tr>

  <tr id="bord">
  <td id="bord" style="width: 10%;">D
  </td>
  <td id="bord" style="width: 35%;"><bold>Heuristic functions</bold> (FC)
  </td>
  <td id="bord" style="width: 55%;">
  <ul>
   <li> Effect of heuristics, generating heuristics, learning heuristics
  </ul>
  </td>
  </tr>
  </table>
  <br>

  <table id="bord" style="width: 100%;">
  <tr id="bord">
  <td id="bord" style="width: 10%;">A
  </td>
  <td id="bord" style="width: 35%;"><bold>Local search</bold> (FC)
  </td>
  <td id="bord" style="width: 55%;">
  <ul>
   <li> Hill-climbing, simulated annealing, local beam search, genetic algorithms
  </ul>
  </td>
  </tr>
  </table>

 </ol>
 [<a href="#top">Top</a>]
 <hr id="dash">

 <a name="Assignments"></a>
 <h2>Problem sets</h2>
 As we use problem set questions covered by books, papers and webpages, we expect you not to copy, refer to, or look at the solutions in preparing your answers. We expect you to want to learn and not google for answers: If you do happen to use other material, it must be acknowledged clearly with a citation on the submitted solution.<br><br> <font color=#333>&#9775;</font> The purpose of problem sets is to help you think about the material, not just give us the right answers.<br><br>

 Homeworks must be done individually: Each of you must hand in his/her own answers. In addition, each of you must write his/her own code when requested. It is acceptable, however, for you to collaborate in figuring out answers. We are assuming that you take the responsibility to make sure you personally understand the solution to any work arising from collaboration (though, <font color="red">you must indicate on each homework with whom you collaborated</font>).
 <br><br>
 <font color=#333>&#9883;</font> To typeset assignments, students are encouraged to use this <a href="https://en.wikipedia.org/wiki/LaTeX">LaTeX</a> template: <a href="2018_2/Additional_stuff/CK0031-CK0248_Exercise_template_2018_2.tex">Source</a> (<a href="2018_2/Additional_stuff/CK0031-CK0248_Exercise_template_2018_2.pdf">PDF</a>).
 <br><br>
 <font color=#333>&#9888;</font> Final projects/assignments must be returned via SIGAA (you'll get notified of the opening of a new task).
 <br>
 <font color="red">Delays will be penalised (<24h, -20% of the grade; <48h, -40% of grade; ...).</font><br><br>

 [<a href="#top">Top</a>]
 <hr id="dash">

 <a name="Material"></a>
 <h2>Material</h2>
 Course slides will suffice. Slides are mostly based on the three following textbooks:
 <ul>
 <li> <bold>Artificial intelligence: A modern approach</bold> (<a href="http://aima.cs.berkeley.edu">Book website</a>), by Stuart Russell and Peter Norvig (tem tradu&ccedil;&atilde;o tamb&eacute;m)
  <li> <bold>Bayesian reasoning and machine learning</bold> (<a href="http://www0.cs.ucl.ac.uk/staff/d.barber/brml">Book website</a>), by David Barber
  <li> <bold>Numerical optimization</bold>, by Jorge Nocedal and S. Wright
 </ul>
 The material can be complemented using material from the following textbooks (list not exhaustive):
 <ol>
  <li> <bold>Probabilistic graphical models: principles and techniques</bold>, by Daphne Koller and Nir Friedman
  <li> <bold>Heuristic Search: Theory and Applications</bold>, by Stefan Edelkamp and Stefan Schr&ouml;dl
 </ol>
 <font color=#333>&#9760;</font> Copies of these books are floating around.<br><br>
 <font color="red"> >>>>>> Course material is prone to a typo or two - Please inbox  FC to report <<<<<< </font>
 <br><br>

 [<a href="#top">Top</a>]
 <hr id="dash">

 <a name="Pops"></a>
 <h2>Read me or watch me</h2>
 <ul>
  <li> ...
 </ul>

 <a href="#top">Top</a>
 <hr id="dash">

</body>
</html>
